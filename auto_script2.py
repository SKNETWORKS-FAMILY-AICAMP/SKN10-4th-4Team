import requests
import pandas as pd
from time import sleep
from tqdm import tqdm
import xml.etree.ElementTree as ET
from urllib.parse import unquote
from dotenv import load_dotenv
import os

# ğŸ”‘ ì¸ì¦ í‚¤ ì„¤ì •
load_dotenv()
ENCODED_KEY = os.getenv("ENCODED_KEY")
if not ENCODED_KEY:
    raise ValueError("âŒ í™˜ê²½ë³€ìˆ˜ 'ENCODED_KEY'ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
API_KEY = unquote(ENCODED_KEY)

# âœ… API URL
BASE_LIST_URL = "https://apis.data.go.kr/B551011/KorService1/areaBasedList1"
DETAIL_URL = "https://apis.data.go.kr/B551011/KorService1/detailCommon1"

# âœ… ìˆ˜ì§‘ ì„¤ì •
TOTAL_COUNT = 51034
PAGE_SIZE = 100
all_items = []
contentid_list = []

# âœ… ìˆ˜ì§‘ ë£¨í”„
try:
    for page in tqdm(range(1, (TOTAL_COUNT // PAGE_SIZE) + 2)):
        params = {
            'serviceKey': API_KEY,
            'numOfRows': PAGE_SIZE,
            'pageNo': page,
            'MobileOS': 'ETC',
            'MobileApp': 'TourCollectorApp',
            '_type': '',
        }

        try:
            res = requests.get(BASE_LIST_URL, params=params, timeout=10)
            res.raise_for_status()

            root = ET.fromstring(res.content)
            items = root.findall(".//item")

            if not items:
                print(f"âš ï¸ [{page}í˜ì´ì§€] í•­ëª© ì—†ìŒ")
                continue

            for item in items:
                data = {child.tag: child.text for child in item}
                contentid = data.get("contentid")

                if not contentid:
                    print(f"â— [page={page}] contentid ëˆ„ë½ â†’ {data.get('title', 'ì œëª© ì—†ìŒ')}")
                    continue

                contentid_list.append(contentid)

                # âœ… ìƒì„¸ì¡°íšŒ
                detail_params = {
                    'serviceKey': API_KEY,
                    'contentId': contentid,
                    'MobileOS': 'ETC',
                    'MobileApp': 'TourCollectorApp',
                    '_type': 'xml',
                    'defaultYN': 'Y',
                    'overviewYN': 'Y',
                }

                try:
                    detail_res = requests.get(DETAIL_URL, params=detail_params, timeout=10)
                    detail_res.raise_for_status()

                    if "xml" in detail_res.headers.get("Content-Type", ""):
                        detail_root = ET.fromstring(detail_res.content)
                        detail_item = detail_root.find(".//item")
                        if detail_item is not None:
                            for child in detail_item:
                                data[child.tag] = child.text
                    else:
                        print(f"[contentid={contentid}] XML ì‘ë‹µ ì•„ë‹˜ â†’ {detail_res.headers.get('Content-Type')}")

                except Exception as de:
                    print(f"[contentid={contentid}] ìƒì„¸ì¡°íšŒ ì‹¤íŒ¨: {de}")

                all_items.append(data)

            sleep(1.2)

        except Exception as e:
            print(f"[page={page}] ëª©ë¡ ì¡°íšŒ ì—ëŸ¬: {e}")
            sleep(3)
            continue

except KeyboardInterrupt:
    print("â›” ì‚¬ìš©ì ì¤‘ë‹¨ ê°ì§€ë¨. ë°ì´í„° ì €ì¥ ì¤‘...")

# âœ… ì €ì¥
if all_items:
    try:
        df = pd.DataFrame(all_items)
        df.to_excel("visitkorea_areaBasedList1_with_detail.xlsx", index=False)
        print("âœ… ì €ì¥ ì™„ë£Œ: visitkorea_areaBasedList1_with_detail.xlsx")
        print(f"ğŸ” ìˆ˜ì§‘ëœ ì „ì²´ í•­ëª© ìˆ˜: {len(all_items)}")
        print(f"ğŸ†” contentid ìˆ˜: {len(contentid_list)}")
    except Exception as save_err:
        print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {type(save_err).__name__} - {save_err}")
else:
    print("âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. API ë˜ëŠ” íŒŒì‹± ì˜¤ë¥˜ í™•ì¸ í•„ìš”.")
