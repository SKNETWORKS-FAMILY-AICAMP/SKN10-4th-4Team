from django.shortcuts import render
from sentence_transformers import SentenceTransformer
import chromadb
from openai import OpenAI
import os
from dotenv import load_dotenv
from django.conf import settings

# ğŸ”¥ chroma_db ê²½ë¡œ â†’ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€
chroma_db_path = os.path.join(settings.BASE_DIR.parent, "chroma_db")

print("ğŸ”¥ ì§€ê¸ˆ ì—°ê²°ëœ ChromaDB ê²½ë¡œ:", chroma_db_path)

# .env íŒŒì¼ ë¡œë“œ
load_dotenv(dotenv_path=os.path.join(settings.BASE_DIR.parent, ".env"))

client = OpenAI(
    api_key=os.getenv("OPENAI_API_KEY")
)

chroma_client = chromadb.PersistentClient(path=chroma_db_path)
collection = chroma_client.get_or_create_collection(name="places")

model = SentenceTransformer("intfloat/e5-large-v2")

def is_recommendation_request(question):
    check_prompt = f"""
    ì•„ë˜ ì‚¬ìš©ì ì§ˆë¬¸ì´ 'ì¥ì†Œ ì¶”ì²œ ìš”ì²­'ì¸ì§€ íŒë‹¨í•´ì¤˜.
    - ë§ìœ¼ë©´ "true", ì•„ë‹ˆë©´ "false"ë§Œ ì¶œë ¥í•´.
    
    ì‚¬ìš©ì ì§ˆë¬¸:
    "{question}"
    """

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": check_prompt}]
    )

    return "true" in response.choices[0].message.content.lower()

def is_follow_up_question(question, chat_history):
    history = ""
    for q, a in chat_history[-3:]:  # ìµœê·¼ 3ê°œë§Œ ì°¸ì¡°
        history += f"ì‚¬ìš©ì: {q}\nì±—ë´‡: {a}\n"

    check_prompt = f"""
    ë‹¤ìŒ ì‚¬ìš©ì ì§ˆë¬¸ì€ ì´ì „ ëŒ€í™”ì˜ ì—°ì¥ì„ ì¸ì§€ íŒë‹¨í•´ì¤˜.
    - ì—°ì†ëœ ì£¼ì œë¼ë©´ "true", ì•„ë‹ˆë©´ "false"ë§Œ ì¶œë ¥í•´.

    ì´ì „ ëŒ€í™”:
    {history}

    í˜„ì¬ ì§ˆë¬¸:
    "{question}"
    """

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": check_prompt}]
    )

    return "true" in response.choices[0].message.content.lower()


def chatbot_view(request):
    answer = ""
    user_question = ""
    region = ""
    category = ""

    # â­ ì„œë²„ ìƒˆë¡œ ì‹œì‘í•  ë•Œë§ˆë‹¤ ì„¸ì…˜ ì´ˆê¸°í™”!
    if not hasattr(request, '_session_initialized'):
        request.session['chat_history'] = []
        request._session_initialized = True

    chat_history = request.session.get('chat_history', [])

    typing = False

    if request.method == "POST":
        user_question = request.POST.get("question")
        region = request.POST.get("region")
        category = request.POST.get("category")

        print("ì‚¬ìš©ì ì§ˆë¬¸:", user_question)
        print("ì„ íƒí•œ ì§€ì—­:", region)
        print("ì„ íƒí•œ ì¹´í…Œê³ ë¦¬:", category)

        typing = True

        is_recommend = is_recommendation_request(user_question)
        is_follow_up = is_follow_up_question(user_question, chat_history)

        # ğŸ”„ ì´ì „ ì¥ì†Œ ì¬í™œìš© íŒë‹¨
        use_last_places = False
        places_info = ""
        last_info = request.session.get("last_places_info")

        if not is_recommend and is_follow_up and last_info:
                places_info = last_info
                use_last_places = True
                print("ğŸ”„ ì´ì „ ì¥ì†Œ ëª©ë¡ ì¬í™œìš© ì¤‘!")
        else:
            print("ğŸ§  ìƒˆ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘!")
            use_last_places = False

        if not use_last_places:
            print("ğŸ§  ìƒˆ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘!")
            query_embedding = model.encode(["query: " + user_question])
            filters = {}
            if category:
                filters["category"] = category  # ğŸ§¼ ì´ê²Œ ê°€ì¥ ì§ê´€ì ì´ê³  ê¹”ë”í•¨

            results = collection.query(
                query_embeddings=query_embedding,
                n_results=10,
                where=filters
            )

            documents = results['documents'][0] if results['documents'][0] else []
            metadatas = results['metadatas'][0] if results['metadatas'][0] else []

            print("ê²€ìƒ‰ëœ ì¥ì†Œ ê°œìˆ˜:", len(documents))

            if documents:
                for doc, meta in zip(documents, metadatas):
                    places_info += f"ì¥ì†Œëª…: {meta['name']}<br>ì¹´í…Œê³ ë¦¬: {meta['category']}<br>ì§€ì—­: {meta['region']}<br>ì„¤ëª…: {doc}<br><br>"

                if is_recommend:
                    request.session["last_places_info"] = places_info
                    print("âœ… ì¥ì†Œ ì¶”ì²œ ì§ˆë¬¸ìœ¼ë¡œ ì¸ì‹ë¨ â†’ ì¥ì†Œ ëª©ë¡ ì„¸ì…˜ ì €ì¥ë¨!")
            else:
                answer = "ì¡°ê±´ì— ë§ëŠ” ì¥ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                chat_history.append((user_question, answer))
                request.session['chat_history'] = chat_history
                typing = False
                return render(request, "index.html", {
                    "answer": answer,
                    "user_question": user_question,
                    "region": region,
                    "category": category,
                    "chat_history": chat_history,
                    "typing": typing
                })
        else:
            print("ğŸ”„ ì´ì „ ì¥ì†Œ ëª©ë¡ ì¬í™œìš© ì¤‘!")
            places_info = last_info

        # ğŸ’¬ GPT í”„ë¡¬í”„íŠ¸ ì¤€ë¹„
        recent_history = chat_history[-5:]

        chat_context = ""
        for past_q, past_a in recent_history:
            chat_context += f"ì‚¬ìš©ì: {past_q}\nì±—ë´‡: {past_a}\n"

        prompt_intro = ""
        if use_last_places:
            prompt_intro = """
            ì´ ì§ˆë¬¸ì€ ì•ì„œ ì¶”ì²œí–ˆë˜ ì¥ì†Œë“¤ì„ ê¸°ì¤€ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ì§ˆë¬¸ì´ì•¼.
            ì•„ë˜ ì¥ì†Œ ëª©ë¡ì€ ê·¸ë•Œ ì¶”ì²œí–ˆë˜ ì¥ì†Œë“¤ì´ê³ ,
            ì´ë²ˆ ì§ˆë¬¸ì€ **ë°˜ë“œì‹œ ì´ ëª©ë¡ ì¤‘ì—ì„œë§Œ** ê³¨ë¼ì•¼ í•´.
            ì ˆëŒ€ ìƒˆ ì¥ì†Œë¥¼ ì¶”ì²œí•˜ì§€ ë§ˆ!
            """

        prompt = f"""
        ë„ˆëŠ” ì‚¬ìš©ìì—ê²Œ ì—¬í–‰ì§€ ì¥ì†Œë¥¼ ì¶”ì²œí•˜ëŠ” ì¹œê·¼í•œ ì±—ë´‡ì´ì•¼.

        ë‹¤ìŒì€ ì§€ê¸ˆê¹Œì§€ ì‚¬ìš©ìì™€ ë‚˜ëˆˆ ëŒ€í™” ê¸°ë¡ì´ì•¼:
        {chat_context}

        ì‚¬ìš©ìê°€ ì§€ê¸ˆ ì´ë ‡ê²Œ ì§ˆë¬¸í–ˆì–´:
        "{user_question}"

        {prompt_intro}

        ì´ ì§ˆë¬¸ì€ ìœ„ì˜ ëŒ€í™” ë§¥ë½ì„ ë°”íƒ•ìœ¼ë¡œ ì´ì–´ì§€ëŠ” ë‚´ìš©ì¼ ìˆ˜ë„ ìˆì–´.
        â†’ ê·¸ëŸ¬ë‹ˆê¹Œ ê¼­ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•´ì„œ ë‹µë³€í•´ì¤˜!

        ì‚¬ìš©ìê°€ ì„¤ì •í•œ ì¡°ê±´:
        - ì§€ì—­: {region}
        - ì¹´í…Œê³ ë¦¬: {category}

        ì•„ë˜ëŠ” ì¶”ì²œì— ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ì¥ì†Œ ëª©ë¡ì´ì•¼:

        {places_info}

        **ì„¤ëª… ë°©ì‹**:
        - ì¶”ì²œ ê°œìˆ˜ë¥¼ ëª…ì‹œí–ˆë‹¤ë©´ í•´ë‹¹ ê°œìˆ˜ë§Œí¼!
        - ëª…ì‹œ ì•ˆ í–ˆë‹¤ë©´ 3~5ê°œë§Œ!
        - ì¹´í…Œê³ ë¦¬ì— ë”°ë¼ ë§íˆ¬ë„ ë‹¤ë¥´ê²Œ!
        - ì‡¼í•‘: ì¹œêµ¬ì²˜ëŸ¼ ë°œë„í•˜ê²Œ
        - ì¹´í˜: ê°ì„±ì ìœ¼ë¡œ
        - ë¬¸í™”ì‹œì„¤: ì¬ë°Œê²Œ, ë†ë‹´ë„ ì¢€ ì„ì–´ì„œ!
        - ì¤„ë°”ê¿ˆì€ <br> íƒœê·¸ë¡œ!
        - ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ, ê°€ë…ì„± ìˆê²Œ!

        **âš ï¸ ì£¼ì˜ì‚¬í•­**:
        - ë°˜ë“œì‹œ ìœ„ì˜ ì¥ì†Œ ëª©ë¡ ì¤‘ì—ì„œë§Œ ê³¨ë¼ì•¼ í•´!
        - ëª©ë¡ì— ì—†ëŠ” ì¥ì†ŒëŠ” ì ˆëŒ€ ì¶”ì²œí•˜ì§€ ë§ˆ!
        """

        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[{"role": "user", "content": prompt}]
        )

        print("GPT ì‘ë‹µ:", response)

        answer = response.choices[0].message.content
        answer = answer.replace("1.", "<br><br>ğŸ› 1.").replace("2.", "<br><br>ğŸ› 2.")
        answer = answer.replace("3.", "<br><br>ğŸ› 3.").replace("4.", "<br><br>ğŸ› 4.")
        answer = answer.replace("\n\n", "<br><br>").replace("\n", "<br>")

        chat_history.append((user_question, answer))
        request.session['chat_history'] = chat_history

        typing = False

    return render(request, "index.html", {
        "answer": answer,
        "user_question": user_question,
        "region": region,
        "category": category,
        "chat_history": chat_history,
        "typing": typing
    })
